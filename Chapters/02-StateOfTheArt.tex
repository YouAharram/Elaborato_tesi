% !TEX root = ../Thesis.tex

\chapter{State of the Art}
Il fenomeno dello speckle è una caratteristica intrinseca delle immagini acquisite da sensori coerenti, 
come i radar ad apertura sintetica (SAR), i sistemi laser o gli interferometri ottici. 
Dal punto di vista fisico, lo speckle nasce dall’interferenza coerente tra le onde elettromagnetiche riflesse 
da molteplici scatterer presenti all’interno di una singola cella di risoluzione del sensore. 
Ciascuno di questi scatterer contribuisce con un segnale complesso avente ampiezza e fase proprie; 
la somma coerente di tali contributi produce una risultante la cui ampiezza varia casualmente nel tempo e nello spazio.  
Questo effetto di interferenza, costruttiva o distruttiva, genera un pattern granulare nell’immagine osservata, 
noto appunto come speckle. Quest'ultimo degrada la qualità visiva e radiometrica dell’immagine, rendendo più complessa l’analisi e l’interpretazione dei dati.
Nello speckle il dominio intensità, è formalmente espresso come:
\[
    \makebox[\textwidth][c]{%
      $\displaystyle
      Z = X \cdot Y
      $%
    }
\]
dove $Z$ rappresenta l'immagine osservata, $X$ è l'immagine originale priva di rumore, 
e $Y$ è la variabile casuale di speckle. Questo modello riflette la natura coerente 
della misura del radar, in cui le ampiezze riflesse da molteplici scatterer all’interno di 
una cella di risoluzione interferiscono tra loro producendo variazioni casuali.
Nel caso di un'immagine \textit{multilook} (media su $L$ osservazioni indipendenti), 
il rumore speckle $Y$ segue una \textit{distribuzione Gamma} con media unitaria:
\begin{equation}
    \makebox[\textwidth][c]{%
      $\displaystyle
      p_Y(y) = \frac{L^L}{\Gamma(L)} y^{L-1} e^{-Ly}, \quad y \ge 0
      $%
    }
  \end{equation}
in cui: $L$ è il numero di \emph{looks} indipendenti; $\Gamma(\cdot)$ è la funzione Gamma;
Questa scelta di modello implica che la varianza dello speckle \textbf{decresce} all'aumentare 
del numero di looks, migliorando la radiometria a scapito della risoluzione \cite{4767223}.
Applicando il logaritmo naturale, il modello moltiplicativo si trasforma 
in un modello additivo
\[
    \makebox[\textwidth][c]{%
      $\displaystyle
      \ln(Z) = \ln(X) + ln(Y)
      $%
    }
\]
dove $\ln(Y)$ rappresenta un rumore additivo con distribuzione derivata da quella Gamma. 
Questo modello è particolarmente utile nei metodi di filtraggio o stima statistica 
che assumono rumori additivi \cite{tutorSpeckle}. 
Negli ultimi trant'anni sono stati proposti numerosi metodi per la riduzione dello speckle nelle immagini SAR.
 I primi approcci sfruttano filti spaziali come Lee, Frost e Kuan \cite{r2024specklenoiseanalysissynthetic}.
Questi operavano direttamente nel dominio dell'immagine, cioè sui pixel, sfruttando finestre locali per stimare
 statisticamente il rumore e ridurlo. Erano strumenti semplici, poco costosi dal punto 
di vista computazionale ed efficaci ma soffrivano di un limite strutturale. Per attenuare lo speckle tendevano a 
smussare anche i dettagli fini, specialmente lungo i bordi o nelle aree eterogenee. 
Con lo sviluppo della teoria delle trasformate multisensoriale negli anni Novanta , si passò ad un approccio diverso. 
Invece di agire direttamente sul'immagine, si inziò a trasformarla in un dominio 
in cui il segnale e il rumore potessero essere seprati. Nascono così i metodi basati su trasformata, come quelli che 
usano wavelet \cite{Argenti2003}  . Questi strumenti rappresentano un'evoluzione concettuale dei filtri spaziali,
perchè superano alcune loro debolezze: riescono a distinguere meglio il rumore dalle strutture significative, ad 
adattarsi a diverse scale ed a preservare in maniera più accurata bordi, texture e linee sottili. 
Tuttavia, portano con sè una maggiore complessità computazionale e la possibilità di introdurre artefatti se non 
calibrati con attenzione. Infine dato che lo speckle è un rumore moltiplicativo e non semplicemente 
additivo, se non viene trasformato prima, la wavelet può non essere del tutto efficace \cite{tutorSpeckle}.
Negli ultimi anni, l'attenzione si è spostata ancora più avanti verso i metodi non locali, come i filtri non local means o 
SARBM3D adattati per le immagini SAR. Qui l'idea è radicalmente diversa, ovvero non ci si limita più a gurdare in un 
introno locale del pixel, ma si cercano nel resto dell'immagine regioni simili e si usano queste 
corrispondenze per ridurre il rumore. In questo modo lo speckle viene attenuato in maniera molto efficace, mentre 
i dettagli strutturali si preservao quasi intatti. La qualità delle immagini risultanti è generalmente
superiore a quella ottenuta con filtri locali o multirisoluzione, ciò comporta però un costo computazionale elevato 
e la necessità di algoritmi sofisticati per gestire le similitudini tra regioni. Negli ultimi dieci 
anni si è aperta una nuova fase, spinta dall'esplosione del deep learning \cite{DL_SAR}. L'idea è che le reti neurali, in 
particolare convoluzionalil o basate su autoencoder, possano imparare direttamente dai dati le caratteristiche
dello speckle e il modo migliore per ridurlo. Questo approccio non si basa più nell'assumere una distribuzione 
statistica del rumore o una struttura matematica da preservare, ma si affida alla capacità della rete di 
apprendere autonomamente dalle coppie di immagini rumorose e pulite. I risultati hanno portato ad una qualità 
visiva migliore e un eccellente preservazione dei dettagli. D'altro canto, le reti neurali hanno bisogno 
di grandi quantità di dati ben calibrati per l'addestramento e possono soffrire di scarsa generalizzazione se 
applicate a scenari diversi da quelli su cui sono state addestrate oltre che ad un costo computazionale molto elevato. 
Le performance dei modelli di despeckling non è uniforme per tutti i tipi di scenari. La loro efficacia può variare
in base alle caratteristiche statistiche del bioma come contesti di vegetazione, aree rocciose e urbane, 
poichè la distribuzione del rumore e le strutture da preservare differiscono sensibilmente. Un'immagine SAR potrebbe 
comprendere due o più tipi di biomi, ciò implica che utlizzando un unico modello di despeckling, 
indipendetemente da quale esso sia, l'immagine risultante avrà aree in cui è stata ripulita meglio e aree in cui è 
stata ripulita peggio a seconda di dove il modello per come è stato realizzato ha più facilità ad operare.
L'idea da cui nasce questa tesi è quello di unire le caratteristiche migliori di determinate tecniche di despeckling, 
in modo tale che l'immagine risultante rispecchi il più possibile la realtà di interesse. Questo tipo di approccio non va a 
reinventare la ruota, cioè non punta a realizzare un nuovo modello con cui è possibile fare denoising, ma è mirato
a sfruttare i punti di forza di modelli già esistenti. Inizialmente è stata usata una tecnica naive che 
prevede un architettura Unet per addestare tanti modelli quante sono le tecniche di despeckling 
della quale si vuole imparare a prevedere la qualità del denoising generando così mappe di qualità 
che determinano quanto dell'immagine denoised di un  modello prendere in relazione alla bontà del denoising.
Questa tecnica però non sfrutta a pieno le qualità dei singoli modelli in quanto la stima della qualità è locale 
e si concentra sul singolo pixel, perdendo informazioni contestuali importanti. 
Inoltre la combinazione pesata a livello di pixel non sfrutta la complementarità tra caratteristiche a livello di 
patch, perciò non valorizza pienamente i punti di forza di ciascun metodo \cite{li2024crossfuse} che sfrutta tecniche basate sull'attenzione 
incrociata. Gli approcci basati su questa tecnica propongono esattamente questa linea di azione: 
invece di pesare singoli pixel, si estraggono rappresentazioni (feature) dai diversi output despeckled e si usa un modulo 
di attenzione per selezionare, a livello di feature e di contesto, quali informazioni preservare e quali attenuare. 
Questo approccio permette di superare i limiti del pixel-per-pixel, in quanto una fusione basata su patch consente 
di catturare informazioni contestuali e di valorizzare le relazioni strutturali presenti nell’immagine. Operando 
su blocchi di feature e non su singoli pixel isolati, il modello è in grado di preservare meglio i bordi e le 
discontinuità, la coerenza spaziale della patch riduce il rischio di smussare i contorni netti, tipico delle 
fusioni locali.